{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVdTpjlHotd2",
        "outputId": "05f5e55f-0635-42dd-870d-13ec04f096e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFGDNuJJrWKn",
        "outputId": "f5884c75-bf5b-4e41-b675-2597cd322c3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTWxS61GhdO3",
        "outputId": "0b7dfa2f-bbe9-462e-c579-a0b180d41cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W-A7-OtL7s-9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from pydub import AudioSegment\n",
        "from io import BytesIO\n",
        "import wave\n",
        "import math\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "47ziMC1A704O"
      },
      "outputs": [],
      "source": [
        "# Define raw audio dictionary\n",
        "raw_audio = {}\n",
        "\n",
        "# Loop through directories and label audio files\n",
        "directories = ['hungry', 'belly_pain', 'burping', 'discomfort', 'tired']\n",
        "for directory in directories:\n",
        "    path = r\"C:/Users/acer/Documents/Cry/cry/donateacry_corpus_cleaned_and_updated_data/\" + directory\n",
        "    for filename in os.listdir(path):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            raw_audio[os.path.join(path, filename)] = directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J7MgUZdVyVtE"
      },
      "outputs": [],
      "source": [
        "# Define function to extract MFCC features and chop audio\n",
        "def extract_mfcc(audio_file, max_length=100):\n",
        "    audiofile, sr = librosa.load(audio_file)\n",
        "    fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=20)\n",
        "    if fingerprint.shape[1] < max_length:\n",
        "        pad_width = max_length - fingerprint.shape[1]\n",
        "        fingerprint_padded = np.pad(fingerprint, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        return fingerprint_padded.T\n",
        "    elif fingerprint.shape[1] > max_length:\n",
        "        return fingerprint[:, :max_length].T\n",
        "    else:\n",
        "        return fingerprint.T\n",
        "\n",
        "\n",
        "# Chop audio and extract MFCC features for each track\n",
        "X = []\n",
        "y = []\n",
        "max_length = 100\n",
        "\n",
        "for i, (audio_file, label) in enumerate(raw_audio.items()):\n",
        "    mfcc_features = extract_mfcc(audio_file, max_length=max_length)\n",
        "    X.append(mfcc_features.flatten())\n",
        "    y.append(label)\n",
        "\n",
        " # Convert features and labels to DataFrame and save to CSV\n",
        "df = pd.DataFrame(X)\n",
        "df = df.fillna(0)\n",
        "df['label'] = y\n",
        "df.to_csv('audio_dataset.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_eXJ6Pf18Nnf"
      },
      "outputs": [],
      "source": [
        "# Convert lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Flatten the features and labels\n",
        "X_flat = X.reshape(X.shape[0], -1)\n",
        "y_flat = y\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_flat, y_flat, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6cbk_h4P8Wm2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train and evaluate models\n",
        "models = [\n",
        "    ('Random Forest', RandomForestClassifier(n_estimators=25, max_features=5)),\n",
        "    ('Logistic Regression', LogisticRegression()),\n",
        "    ('Decision Tree', DecisionTreeClassifier()),\n",
        "    ('SVM', SVC()),\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFSjIisU-Bj9",
        "outputId": "3fccdd46-a6c8-4eef-a6c2-bea03066810f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model, Accuracy, Precision, Recall\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest: 0.7934782608695652, 0.6296077504725898, 0.7934782608695652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression: 0.6630434782608695, 0.6205406911928651, 0.6630434782608695\n",
            "Decision Tree: 0.6847826086956522, 0.6633221850613155, 0.6847826086956522\n",
            "SVM: 0.7934782608695652, 0.6296077504725898, 0.7934782608695652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"Model, Accuracy, Precision, Recall\")\n",
        "for model_name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    print(f\"{model_name}: {accuracy}, {precision}, {recall}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdH0N-idBi08",
        "outputId": "42b21197-82ba-44ae-e1e8-310a6e1df7dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(364, 2000)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-BdnDwr_c1N",
        "outputId": "db8c04ed-f59a-4cc4-bc51-7d5451190190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 6s 220ms/step - loss: 1.4171 - accuracy: 0.4467 - val_loss: 0.7885 - val_accuracy: 0.8630\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.7237 - accuracy: 0.8419 - val_loss: 0.5759 - val_accuracy: 0.8630\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 1s 132ms/step - loss: 0.6464 - accuracy: 0.8454 - val_loss: 0.6108 - val_accuracy: 0.8630\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 1s 134ms/step - loss: 0.6424 - accuracy: 0.8454 - val_loss: 0.6061 - val_accuracy: 0.8630\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 0.6100 - accuracy: 0.8454 - val_loss: 0.5981 - val_accuracy: 0.8630\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.5954 - accuracy: 0.8454 - val_loss: 0.6038 - val_accuracy: 0.8630\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 2s 233ms/step - loss: 0.5824 - accuracy: 0.8454 - val_loss: 0.5815 - val_accuracy: 0.8630\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 2s 238ms/step - loss: 0.5841 - accuracy: 0.8454 - val_loss: 0.5768 - val_accuracy: 0.8630\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.5561 - accuracy: 0.8454 - val_loss: 0.5793 - val_accuracy: 0.8630\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.5417 - accuracy: 0.8488 - val_loss: 0.5733 - val_accuracy: 0.8630\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.8692 - accuracy: 0.7935\n",
            "Accuracy: 0.79347825050354\n",
            "3/3 [==============================] - 1s 45ms/step\n",
            "Precision: 0.6296077504725898\n",
            "Recall: 0.7934782608695652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Reshape data for LSTM input\n",
        "n_samples, n_features = X_train.shape[0], X_train.shape[1] // 100\n",
        "n_timesteps = 100\n",
        "X_train_lstm = X_train.reshape((n_samples, 100, 20))\n",
        "n_samples_test = X_test.shape[0]\n",
        "X_test_lstm = X_test.reshape((n_samples_test, n_timesteps, n_features))\n",
        "\n",
        "# Convert labels to numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Define LSTM model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(units=128, input_shape=(n_timesteps, n_features)),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=len(np.unique(y_train_encoded)), activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Compile LSTM model\n",
        "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train LSTM model\n",
        "lstm_model.fit(X_train_lstm, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate LSTM model\n",
        "_, accuracy = lstm_model.evaluate(X_test_lstm, y_test_encoded)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Predict probabilities for the test dataset using the trained LSTM model\n",
        "predicted_probabilities = lstm_model.predict(X_test_lstm)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test_encoded, predicted_labels, average='weighted')\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test_encoded, predicted_labels, average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4Ll8k9I0NzE",
        "outputId": "5cdf2450-a0f7-4e3c-c075-56c6739aa67c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lstm_audio_model.joblib']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(lstm_model, \"lstm_audio_model.joblib\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yhf5-K372ez0"
      },
      "outputs": [],
      "source": [
        "def pickle_model(model, modelname):\n",
        "    directory = 'models'\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    with open(os.path.join(directory, str(modelname) + '.pkl'), 'wb') as f:\n",
        "        return pickle.dump(model, f)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "pickle_model(model, \"myRandomForest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJC2hBXJogh8"
      },
      "outputs": [],
      "source": [
        "def getModel(pickle_path):\n",
        "  with open(pickle_path, 'rb') as f:\n",
        "        return pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypgf53c-1zGb",
        "outputId": "12d3be75-a6ca-4073-c47d-becb255c929d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pur_4ZQw8kT2",
        "outputId": "8a58767e-6e81-4db6-b512-4f9bc3093859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio chopped successfully!\n"
          ]
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "from pydub import AudioSegment\n",
        "import wave\n",
        "import math\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "# Define the function to chop the audio\n",
        "def chop_new_audio(audio_data, folder):\n",
        "    os.makedirs(folder, exist_ok=True)  # Create directory if it doesn't exist\n",
        "    audio = wave.open(audio_data, 'rb')\n",
        "    frame_rate = audio.getframerate()\n",
        "    n_frames = audio.getnframes()\n",
        "    window_size = 2 * frame_rate\n",
        "    num_secs = int(math.ceil(n_frames / frame_rate))\n",
        "    last_number_frames = 0\n",
        "    for i in range(num_secs):\n",
        "        shortfilename = str(uuid.uuid4())  # Generate a unique filename\n",
        "        snippetfilename = f\"{folder}/{shortfilename}snippet{i+1}.wav\"\n",
        "        snippet = wave.open(snippetfilename, 'wb')\n",
        "        snippet.setnchannels(2)\n",
        "        snippet.setsampwidth(audio.getsampwidth())\n",
        "        snippet.setframerate(frame_rate)\n",
        "        snippet.setnframes(audio.getnframes())\n",
        "        snippet.writeframes(audio.readframes(window_size))\n",
        "        audio.setpos(audio.tell() - 1 * frame_rate)\n",
        "\n",
        "         # Check if the frame size of the snippet matches the previous snippets\n",
        "        if last_number_frames < 1:\n",
        "            last_number_frames = snippet.getnframes()\n",
        "        elif snippet.getnframes() != last_number_frames:\n",
        "            os.rename(snippetfilename, f\"{snippetfilename}.bak\")\n",
        "        snippet.close()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Example of reading audio data from a file-like object (e.g., uploaded file)\n",
        "    with open('hungry baby.mp3', 'rb') as f:\n",
        "        mp3_data = f.read()\n",
        "\n",
        "    audio = AudioSegment.from_mp3(BytesIO(mp3_data))\n",
        "    wav_data = BytesIO()\n",
        "    audio.export(wav_data, format=\"wav\")\n",
        "    wav_data.seek(0)\n",
        "\n",
        "    folder_name = \"samples\"\n",
        "    chop_new_audio(wav_data, folder_name)\n",
        "    print(\"Audio chopped successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc22mK_i8r4m",
        "outputId": "b20b2e19-05e8-4f9e-9663-b1180838cb70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('discomfort', 26), ('tired', 1), ('hungry', 1)]\n",
            "[('discomfort', 26)]\n"
          ]
        }
      ],
      "source": [
        "# Predict on new audio snippets\n",
        "predictions = []\n",
        "\n",
        "folder_path = 'samples/'\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audiofile, sr = librosa.load(os.path.join(folder_path, filename))\n",
        "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=20)\n",
        "        fingerprint_flat = fingerprint.reshape(-1)  # Flatten the MFCC features\n",
        "        # Pad or truncate features to match the number of features used for training\n",
        "        if len(fingerprint_flat) < 2000:\n",
        "            fingerprint_flat = np.pad(fingerprint_flat, (0, 2000 - len(fingerprint_flat)))\n",
        "        elif len(fingerprint_flat) > 2000:\n",
        "            fingerprint_flat = fingerprint_flat[:2000]\n",
        "        prediction = model.predict([fingerprint_flat])  # Reshape to match expected input format\n",
        "        predictions.append(prediction[0])\n",
        "\n",
        "from collections import Counter\n",
        "data = Counter(predictions)\n",
        "print(data.most_common())  # Returns all unique items and their counts\n",
        "print(data.most_common(1))  # Returns the most common prediction\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
